import os
import sys
import subprocess
import json
import re
import io
import time
import pandas as pd
from dotenv import load_dotenv
import streamlit as st
from PyPDF2 import PdfReader 
import google.generativeai as genai
from google.generativeai import types
from google.generativeai.types import GenerationConfig 
from typing import Dict, Any, Tuple
import altair as alt 


# --- 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î Environment ---
load_dotenv()
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', '').strip()

# ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ 
GEMINI_BATCH_MODEL_NAME = "gemini-2.5-flash" 

GEMINI_AVAILABLE = False
try:
    if GEMINI_API_KEY and len(GEMINI_API_KEY) > 30:
        genai.configure(api_key=GEMINI_API_KEY)
        GEMINI_AVAILABLE = True
except Exception:
    GEMINI_AVAILABLE = False


# Initialize session states
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'last_uploaded_file_name' not in st.session_state:
    st.session_state.last_uploaded_file_name = None
if 'question_texts' not in st.session_state:
    st.session_state.question_texts = None


# --- 2. ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Prompt Template ---
def load_prompts() -> Tuple[str, str]:
    """‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ Prompt Template ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå 'Prompt.txt' ‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡πÄ‡∏õ‡πá‡∏ô System/Chat"""
    prompt_path = os.path.join(os.path.dirname(__file__), 'Prompt.txt')
    try:
        with open(prompt_path, 'r', encoding='utf-8') as f:
            full_content = f.read()
            
            # 1. System Instruction
            system_match = full_content.split("# --- END_SYSTEM_INSTRUCTION_ANALYSIS_MODE ---")[0]
            SYSTEM_INSTRUCTION_PROMPT = system_match.strip() if system_match else "You are a test expert for Thai curriculum. Analyze the question and return a JSON object."
            
            # 2. Few-Shot Template 
            chat_match = full_content.split("# --- CHAT_PROMPT ---")
            
            if len(chat_match) > 1:
                # ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô Prompt Template ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                template_content = chat_match[1].split("# --- CHAT_PROMPT_END ---")[0].strip()
                # ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏° {user_query} ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡πâ‡∏≤‡∏¢
                FEW_SHOT_PROMPT_TEMPLATE = template_content + "\n{user_query}"
            else:
                FEW_SHOT_PROMPT_TEMPLATE = "Analyze the following question/text and return the JSON object: {user_query}"

            return SYSTEM_INSTRUCTION_PROMPT, FEW_SHOT_PROMPT_TEMPLATE
    except FileNotFoundError:
        return (
            "# Error: Prompt file not found. Fallback to default instruction.", 
            "Analyze the following question/text and return the JSON object: {user_query}"
        )

SYSTEM_INSTRUCTION_PROMPT, FEW_SHOT_PROMPT_TEMPLATE = load_prompts()


# --- 3. Helper Functions ---

BLOOM_COLORS = {
    "REMEMBER": "#6495ED",  
    "UNDERSTAND": "#40E0D0",
    "APPLY": "#50C878",     
    "ANALYZE": "#8FBC8F",   
    "EVALUATE": "#ADFF2F",  
    "CREATE": "#FFD700",    
    "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏": "#A9A9A9",
    "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ": "#A9A9A9"
}

def get_bloom_color(level):
    """‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡∏£‡∏´‡∏±‡∏™‡∏™‡∏µ Hex ‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom's Taxonomy"""
    if not level:
        return BLOOM_COLORS['‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏']
    
    level_upper = level.strip().upper()
    for key, color in BLOOM_COLORS.items():
        if key in level_upper:
            return color
    return BLOOM_COLORS['‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'] # Fallback

def get_text_color_for_bloom(level):
    """‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏î‡∏Å‡∏±‡∏ö‡∏™‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô)"""
    level_upper = level.strip().upper()
    if level_upper in ['EVALUATE', 'CREATE']: # ‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á/‡∏ó‡∏≠‡∏á/‡∏™‡∏ß‡πà‡∏≤‡∏á ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏™‡∏µ‡∏î‡∏≥
        return 'black' 
    return 'white' # ‡∏™‡∏µ‡πÄ‡∏Ç‡πâ‡∏°‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß


def extract_text_from_pdf(pdf_reader):
    """‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ PdfReader"""
    text = ""
    for page in pdf_reader.pages:
        try:
            page_text = page.get_text() if hasattr(page, 'get_text') else page.extract_text()
            text += (page_text or "") + "\n"
        except Exception:
            text += "\n"
    return text.strip()

def clean_and_normalize(text):
    """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏•‡∏Ç‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡∏≠‡∏≤‡∏£‡∏ö‡∏¥‡∏Å"""
    if not text: return ""
    # 1. ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏•‡∏Ç‡πÑ‡∏ó‡∏¢
    thai_digits = "‡πê‡πë‡πí‡πì‡πî‡πï‡πñ‡πó‡πò‡πô"
    for i, digit in enumerate(thai_digits):
        text = text.replace(digit, str(i))
    
    # 2. ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á
    text = re.sub(r'[ \t]+', ' ', text) 
    text = text.replace('\r', '')
    
    # 3. ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ö‡∏à‡∏∏‡∏î (‡πÄ‡∏ä‡πà‡∏ô ‡∏Å . -> ‡∏Å.)
    text = re.sub(r'([‡∏Å-‡∏áA-D])\s*\.', r'\1.', text)
    
    # 4. ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ö‡∏à‡∏∏‡∏î (‡πÄ‡∏ä‡πà‡∏ô 1 . -> 1.)
    text = re.sub(r'(\d+)\s*\.', r'\1.', text)
    
    # 5. ‡∏•‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
    text = re.sub(r'\n{2,}', '\n', text)
    
    lines = [line.strip() for line in text.split('\n')]
    return '\n'.join(lines)

def extract_questions(raw_text):
    """
    ‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠ (‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà 1-99 ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡∏Å. ‡∏Ç.)
    """
    # 1. ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    # ‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô "‡πÄ‡∏â‡∏•‡∏¢" ‡∏ó‡∏¥‡πâ‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏≠‡∏á
    text = re.split(r"={10,}\s*‡πÄ‡∏â‡∏•‡∏¢\s*={10,}", raw_text, flags=re.DOTALL | re.IGNORECASE)[0]
    cleaned_text = clean_and_normalize(text)
    
    # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Regex ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠ (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÅ‡∏Ñ‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç 1-99)
    question_prefix = r'(?:[1-9]\d?\.|\([1-9]\d?\))\s*' 
    
    # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Regex ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (Thai/English)
    option_marker = r'(?:‡∏Å\.\s*|A\.\s*)'
    
    # 4. ‡∏£‡∏ß‡∏° Regex: ‡∏à‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠ (1-99) ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡∏Å./A. ‡∏ï‡∏≤‡∏°‡∏°‡∏≤
    pattern = r'(\s*' + question_prefix + r'.*?' + option_marker + r'.*?)(?=\s*' + question_prefix + r'|\s*$)'
    
    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    matches = re.findall(pattern, cleaned_text, flags=re.DOTALL | re.IGNORECASE)
    
    questions = []
    
    # 5. ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
    for m in matches:
        q = m.strip()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡∏Å-‡∏á ‡∏´‡∏£‡∏∑‡∏≠ A-D ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏ï‡∏±‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        option_count_thai = len(re.findall(r'[‡∏Å-‡∏á]\s*\.', q))
        option_count_eng = len(re.findall(r'[A-D]\s*\.', q))
        
        # ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç: ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏ï‡∏±‡∏ß
        if option_count_thai >= 2 or option_count_eng >= 2:
            # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡πâ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà
            q_formatted = re.sub(r'(\s*[‡∏Å‡∏Ç‡∏Ñ‡∏á]\s*\.)', r'\n\1', q)
            q_formatted = re.sub(r'(\s*[A-D]\s*\.)', r'\n\1', q_formatted)
            questions.append(q_formatted.strip())
        
    return questions


def analyze_with_gemini(question_text, question_id=1):
    """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Gemini API ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö (10 Fields Logic)"""
    if not GEMINI_AVAILABLE:
        return {
            "bloom_level": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "reasoning": "‡πÑ‡∏°‡πà‡∏û‡∏ö API Key",
            "difficulty": "‡πÑ‡∏°‡πà‡πÄ‡∏°‡∏¥‡∏ô", "curriculum_standard": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏",
            "correct_option": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "correct_option_analysis": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ AI",
            "distractor_analysis": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ AI", "why_good_distractor": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ AI",
            "is_good_question": False, "improvement_suggestion": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ: ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key"
        } 

    model = genai.GenerativeModel(
        GEMINI_BATCH_MODEL_NAME, 
        system_instruction=SYSTEM_INSTRUCTION_PROMPT
    )
    
    question_text_formatted = f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà {question_id}:\n{question_text}"
    
    # ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Prompt ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    full_prompt = FEW_SHOT_PROMPT_TEMPLATE.format(user_query=question_text_formatted) 
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î JSON Schema (10 Fields)
    json_schema = {
        "type": "object",
        "properties": {
            "bloom_level": {"type": "string"},
            "reasoning": {"type": "string"},
            "difficulty": {"type": "string"},
            "curriculum_standard": {"type": "string"},
            "correct_option": {"type": "string"},
            "correct_option_analysis": {"type": "string"},
            "distractor_analysis": {"type": "string"},
            "why_good_distractor": {"type": "string"},
            "is_good_question": {"type": "boolean"},
            "improvement_suggestion": {"type": "string"}
        },
        "required": [
            "bloom_level", "reasoning", "difficulty", "curriculum_standard",
            "correct_option", "correct_option_analysis", "distractor_analysis",
            "why_good_distractor", "is_good_question", "improvement_suggestion"
        ]
    }

    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Config (‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö JSON ‡πÅ‡∏•‡∏∞‡∏•‡∏î Temperature)
    config = GenerationConfig( 
        response_mime_type="application/json", 
        response_schema=json_schema, 
        temperature=0.0
    )
    
    last_error_message = ""

    for attempt in range(3):
        delay = 2 ** attempt
        if attempt > 0:
            time.sleep(delay)
            
        try:
            response = model.generate_content(
                full_prompt, 
                generation_config=config, 
            )
            raw_text = response.text.strip()
        
            # Hardened JSON Cleaning/Extraction
            cleaned_json = re.sub(r'^```(?:json)?\s*|```$', '', raw_text, flags=re.MULTILINE | re.DOTALL).strip()
            start_brace = cleaned_json.find('{')
            end_brace = cleaned_json.rfind('}')
            
            if start_brace != -1 and end_brace != -1 and end_brace > start_brace:
                cleaned_json = cleaned_json[start_brace:end_brace+1].strip()
            else:
                raise ValueError("Could not find valid JSON structure (missing { or }).") 
            
            # ‡πÇ‡∏´‡∏•‡∏î JSON
            analysis = json.loads(cleaned_json)
            
            # Data sanitation and Key validation
            required_keys = [
                "bloom_level", "reasoning", "difficulty", "curriculum_standard",
                "correct_option", "correct_option_analysis", "distractor_analysis",
                "why_good_distractor", "is_good_question", "improvement_suggestion"
            ]
            
            def safe_str(val): return str(val).strip() if val is not None else "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
            def safe_bool(val):
                if isinstance(val, str): 
                    return val.lower().strip() == 'true'
                if val in (True, False): return val
                return False

            final_analysis = {}
            for key in required_keys:
                raw_val = analysis.get(key)
                if key == "is_good_question":
                    final_analysis[key] = safe_bool(raw_val)
                else:
                    final_analysis[key] = safe_str(raw_val if raw_val is not None else "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
                
                if key not in analysis:
                    raise KeyError(f"JSON Output is missing required key: {key}")

            return final_analysis

        except (json.JSONDecodeError, ValueError, KeyError) as e:
            last_error_message = f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• JSON/Key: {type(e).__name__}: {str(e)}"
            
            if "429" in str(e) or "quota" in str(e).lower():
                last_error_message = f"QUOTA EXCEEDED: ‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤ {GEMINI_BATCH_MODEL_NAME} ‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡πâ‡∏ß ({e})"
                break
            
            continue # ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà (Retry)

    # Fallback ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢: ‡∏´‡∏≤‡∏Å AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
    return {
        "bloom_level": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ", "reasoning": "AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß",
        "difficulty": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÑ‡∏î‡πâ", "curriculum_standard": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ",
        "correct_option": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "correct_option_analysis": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏",
        "distractor_analysis": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "why_good_distractor": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏",
        "is_good_question": False, 
        "improvement_suggestion": f"**‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå** (‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ 3 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á): {last_error_message}"
    }


def check_bloom_criteria(analysis_results):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà."""
    total = len(analysis_results)
    if total == 0: 
        return {"pass": False, "reason": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö", "percentages": {}, "raw_counts": {}, "valid_total": 0} 

    # Standardized Level Names for grouping
    LEVEL_GROUPS = {
        "Remember": 0, "Understand": 0, "Apply": 0, 
        "Analyze": 0, "Evaluate": 0, "Create": 0, "Unknown": 0
    }
    
    for item in analysis_results:
        level = str(item.get("bloom_level", "")).strip().lower()
        if "remember" in level: LEVEL_GROUPS["Remember"] += 1
        elif "understand" in level: LEVEL_GROUPS["Understand"] += 1
        elif "apply" in level: LEVEL_GROUPS["Apply"] += 1
        elif "analyze" in level: LEVEL_GROUPS["Analyze"] += 1
        elif "evaluate" in level: LEVEL_GROUPS["Evaluate"] += 1
        elif "create" in level: LEVEL_GROUPS["Create"] += 1
        else: LEVEL_GROUPS["Unknown"] += 1

    apply_analyze_count = LEVEL_GROUPS["Apply"] + LEVEL_GROUPS["Analyze"]
    remember_understand_count = LEVEL_GROUPS["Remember"] + LEVEL_GROUPS["Understand"]
    evaluate_create_count = LEVEL_GROUPS["Evaluate"] + LEVEL_GROUPS["Create"]
    valid_total = total - LEVEL_GROUPS["Unknown"] # ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom ‡πÑ‡∏î‡πâ

    if valid_total == 0:
        return {"pass": False, "reason": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢", "percentages": {}, "raw_counts": LEVEL_GROUPS, "valid_total": 0} 
        
    percent = {
        "Remember/Understand": round((remember_understand_count / valid_total) * 100, 1) if valid_total > 0 else 0,
        "Apply/Analyze": round((apply_analyze_count / valid_total) * 100, 1) if valid_total > 0 else 0,
        "Evaluate/Create": round((evaluate_create_count / valid_total) * 100, 1) if valid_total > 0 else 0
    }

    # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏ï‡πà‡∏≥ ‚â§ 40%, ‡∏Å‡∏•‡∏≤‡∏á ‚â• 50%, ‡∏™‡∏π‡∏á ‚â• 10%)
    pass_r_u = percent["Remember/Understand"] <= 40
    pass_a_a = percent["Apply/Analyze"] >= 50
    pass_e_c = percent["Evaluate/Create"] >= 10
    passed = pass_r_u and pass_a_a and pass_e_c

    reason = "‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏ú‡πà‡∏≤‡∏ô** ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î (Bloom)" if passed else "‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô** ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î (Bloom)"

    return {
        "pass": passed,
        "reason": reason,
        "percentages": percent,
        "raw_counts": LEVEL_GROUPS,
        "valid_total": valid_total 
    }

def create_analysis_report(all_analysis, bloom_check):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞ DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•"""
    total_questions = len(all_analysis)
    
    failed_analysis = sum(1 for a in all_analysis if "QUOTA EXCEEDED" in a.get('improvement_suggestion', '') or "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå" in a.get('improvement_suggestion', ''))
    
    successfully_analyzed_questions = total_questions - failed_analysis
    good_questions = sum(1 for a in all_analysis if a.get('is_good_question') is True and a.get('bloom_level') != "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ")

    summary_data = {
        "‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°": {
            "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î": f"{total_questions} ‡∏Ç‡πâ‡∏≠",
            "‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à": f"{successfully_analyzed_questions} ‡∏Ç‡πâ‡∏≠",
            "‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏î‡∏µ** (‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)": f"{good_questions} ‡∏Ç‡πâ‡∏≠ ({round((good_questions/successfully_analyzed_questions)*100, 1) if successfully_analyzed_questions > 0 else 0}%)",
            "‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á**": f"{successfully_analyzed_questions - good_questions} ‡∏Ç‡πâ‡∏≠ ({round(((successfully_analyzed_questions - good_questions)/successfully_analyzed_questions)*100, 1) if successfully_analyzed_questions > 0 else 0}%)"
        },
        "‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î": {
            "‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°": bloom_check['reason'],
            "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏ï‡πà‡∏≥ (‡∏à‡∏≥/‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à) (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â§ 40%)": f"{bloom_check['percentages'].get('Remember/Understand', 0)}%",
            "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏Å‡∏•‡∏≤‡∏á (‡πÉ‡∏ä‡πâ/‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå) (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â• 50%)": f"{bloom_check['percentages'].get('Apply/Analyze', 0)}%", 
            "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏π‡∏á (‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô/‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå) (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â• 10%)": f"{bloom_check['percentages'].get('Evaluate/Create', 0)}%",
            "‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ": f"{bloom_check['raw_counts'].get('Unknown', 0)} ‡∏Ç‡πâ‡∏≠",
            "raw_counts": bloom_check['raw_counts'],
            "valid_total": bloom_check.get('valid_total', 0)
        }
    }
    
    df_data = []
    for i, item in enumerate(all_analysis):
        is_good = "‚úÖ ‡∏î‡∏µ" if item.get('is_good_question') is True and item.get('bloom_level') != "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ" else "‚ùå ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á/‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß"
        df_data.append({
            '‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà': i + 1,
            '‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö': is_good,
            '‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î': item.get('bloom_level', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
            '‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£': item.get('curriculum_standard', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
            '‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö': item.get('correct_option', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
            '‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠': item.get('reasoning', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•'),
            '‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞': item.get('improvement_suggestion', '‡πÑ‡∏°‡πà‡∏°‡∏µ'),
            '‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏ï‡πá‡∏°': item.get('question_text', '')
        })
    df = pd.DataFrame(df_data)
    return summary_data, df

# --- 4. Main App Function (UI) ---

def run_app():
    # üé® ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
    st.set_page_config(
        page_title="‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (Gemini AI)",
        page_icon="üìù", 
        layout="wide",
        initial_sidebar_state="auto", 
        menu_items=None
    )
    
    st.title("‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ ü§ñ‚ú®") 
    st.markdown(
        """
        ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ **Gemini AI** ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏ô‡∏±‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡πÅ‡∏Å‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡∏Ø
        ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏ï‡∏≤‡∏° **Bloom‚Äôs Taxonomy** ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö.
        """
    )
    st.markdown("---") 

    
    with st.sidebar:
        st.header("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ & ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ AI")
        
        if GEMINI_AVAILABLE:
            st.success("‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ AI ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        else:
            st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key (GEMINI_API_KEY) - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô `.env`")
        
        st.markdown("**‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô**")
        st.info(f"Batch Analysis: `{GEMINI_BATCH_MODEL_NAME}`") 
        st.markdown("---")
        st.subheader("üí° ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö")
        st.markdown("- ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå **PDF** ‡∏´‡∏£‡∏∑‡∏≠ **TXT**")
        st.markdown("- ‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ **‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠** (‡πÄ‡∏ä‡πà‡∏ô 1., 2.) ‡πÅ‡∏•‡∏∞ **‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å** (‡πÄ‡∏ä‡πà‡∏ô ‡∏Å., ‡∏Ç.)")

        if not GEMINI_AVAILABLE:
            st.warning("‡πÇ‡∏õ‡∏£‡∏î‡∏ó‡∏£‡∏≤‡∏ö: ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GEMINI_API_KEY ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")

    # --- Step 1: Upload ---
    st.header("1Ô∏è‚É£ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö (Batch Analysis)")
    with st.container(border=True):
        uploaded_file = st.file_uploader(
            "üìÅ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **(.PDF ‡∏´‡∏£‡∏∑‡∏≠ .TXT)**", 
            type=['pdf', 'txt'], 
            accept_multiple_files=False, 
            key='file_uploader_widget', 
            label_visibility="collapsed"
        )

        if uploaded_file is not None:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if uploaded_file.name != st.session_state.last_uploaded_file_name:
                st.session_state.analysis_results = None
                st.session_state.last_uploaded_file_name = uploaded_file.name
                st.session_state.question_texts = None
                
            if st.session_state.question_texts is None:
                file_extension = uploaded_file.name.split('.')[-1].lower()
                
                # Custom Loading UI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö
                status_container = st.empty()
                status_container.info(f"‚è≥ **‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö:**\n\n‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå **{uploaded_file.name}**...")
                
                with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°..."):
                    try:
                        if file_extension == 'pdf':
                            with io.BytesIO(uploaded_file.getvalue()) as open_pdf_file:
                                pdf_reader = PdfReader(open_pdf_file)
                                raw_text = extract_text_from_pdf(pdf_reader)
                        elif file_extension == 'txt':
                            raw_text = uploaded_file.getvalue().decode("utf-8")
                        
                        question_texts = extract_questions(raw_text)
                        st.session_state.question_texts = question_texts
                        
                        status_container.empty() # ‡∏•‡πâ‡∏≤‡∏á Custom Loading
                        
                        if not question_texts:
                            st.error("‚ùå **‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö** ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå (‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠/‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ)")
                            st.info("üí° **‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå:** ‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ **‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠** ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (‡πÄ‡∏ä‡πà‡∏ô 1., 2., 3.) ‡πÅ‡∏•‡∏∞‡∏°‡∏µ **‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å** (‡πÄ‡∏ä‡πà‡∏ô ‡∏Å., ‡∏Ç., ‡∏Ñ., ‡∏á.)")
                            return 
                        
                    except Exception as e:
                        status_container.empty() # ‡∏•‡πâ‡∏≤‡∏á Custom Loading
                        st.error(f"‚ùå **‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå:** {e}")
                        return 
                
                # Rerun ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏™‡∏Å‡∏±‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                st.rerun() 

            question_texts = st.session_state.question_texts
            if question_texts:
                st.success(f"‚úÖ ‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß **{len(question_texts)} ‡∏Ç‡πâ‡∏≠** ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå `{uploaded_file.name}`")
            


    # --- Step 2: Start Analysis ---
    st.markdown("---")
    st.header("2Ô∏è‚É£ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô üöÄ")
    
    # ‡πÉ‡∏ä‡πâ Callback function ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Rerun ‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô)
    def start_analysis_callback():
        if not GEMINI_AVAILABLE:
            st.error("Key ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")
            return
            
        question_texts = st.session_state.question_texts
        analysis_results = []
        
        # ‡πÉ‡∏ä‡πâ st.status ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        with st.status("üöÄ **‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ AI...**", expanded=True) as status_box:
            
            st.write(f"‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö {len(question_texts)} ‡∏Ç‡πâ‡∏≠ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ `{GEMINI_BATCH_MODEL_NAME}`")
            progress_bar = st.progress(0, text=f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö 0/{len(question_texts)} ‡∏Ç‡πâ‡∏≠...")
            
            for i, q_text in enumerate(question_texts):
                st.write(f"ü§ñ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà {i+1}...")
                analysis = analyze_with_gemini(q_text, question_id=i+1)
                analysis["question_text"] = q_text 
                analysis_results.append(analysis)
                
                progress_percent = (i + 1) / len(question_texts)
                progress_bar.progress(progress_percent, text=f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö {i+1}/{len(question_texts)} ‡∏Ç‡πâ‡∏≠...")
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á‡πÉ‡∏ô session state
            st.session_state.analysis_results = analysis_results
            
            # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
            status_box.update(label="üéâ **‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!**", state="complete", expanded=False)


    if st.session_state.question_texts and st.button(
        "üöÄ **‡∏Å‡∏î‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ AI**", 
        type="primary", 
        use_container_width=True,
        on_click=start_analysis_callback 
    ):
        pass


    # --- Step 3: Report ---
    if st.session_state.analysis_results:
        st.divider()
        st.header("3Ô∏è‚É£ ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö üìù")

        all_analysis = st.session_state.analysis_results
        successful_analysis = [a for a in all_analysis if a.get('bloom_level') != "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ"]
        bloom_check = check_bloom_criteria(successful_analysis)
        summary_data, df = create_analysis_report(all_analysis, bloom_check)
        
        # ‡∏î‡∏∂‡∏á valid_total ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á (‡πÅ‡∏Å‡πâ NameError)
        valid_total = summary_data["‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î"].get("valid_total", 0)

        # ‡πÉ‡∏ä‡πâ Tabs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
        # *** ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏•‡∏ö tab_raw ‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ ***
        tab_summary, tab_details = st.tabs(["üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô & ‡πÄ‡∏Å‡∏ì‡∏ë‡πå Bloom", "üìù ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠"])

        # --- Tab: Summary ---
        with tab_summary:
            st.subheader("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö")
            stats = summary_data["‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°"]
            col1, col2, col3, col4 = st.columns(4) 

            # Helper function to extract percent value
            def get_percent_delta(text):
                try: 
                    return text.split('(')[1].strip('%)') 
                except IndexError: 
                    return "0.0%"

            # Good Questions Metric
            good_count_str = stats["‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏î‡∏µ** (‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)"].split(' ')[0]
            good_percent_str = get_percent_delta(stats["‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏î‡∏µ** (‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)"])
            col1.metric("‚úÖ ‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ", good_count_str, delta=f"{good_percent_str}%", delta_color="normal")
            
            # To Improve Metric
            improve_count_str = stats["‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á**"].split(' ')[0]
            improve_percent_str = get_percent_delta(stats["‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á**"])
            col2.metric("‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á", improve_count_str, delta=f"{improve_percent_str}%", delta_color="inverse")
            
            # Total Questions 
            col3.metric("üìù ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", stats["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"].split(' ')[0])
            
            # Successfully Analyzed
            col4.metric("ü§ñ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à", stats["‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à"].split(' ')[0])
            
            st.markdown("---")
            st.subheader("üí° ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î (Bloom)")
            bloom_stats = summary_data["‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î"]
            
            if bloom_check['pass']:
                st.success(f"**üéâ {bloom_stats['‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°']}**")
            else:
                st.warning(f"**‚ùå {bloom_stats['‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°']}**")
                
            col_b1, col_b2, col_b3 = st.columns(3)
            col_b1.metric("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏ï‡πà‡∏≥ (‡∏à‡∏≥/‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à)", bloom_stats["‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏ï‡πà‡∏≥ (‡∏à‡∏≥/‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à) (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â§ 40%)"], delta="‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â§ 40%")
            col_b2.metric("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏Å‡∏•‡∏≤‡∏á (‡πÉ‡∏ä‡πâ/‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå)", bloom_stats["‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏Å‡∏•‡∏≤‡∏á (‡πÉ‡∏ä‡πâ/‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå) (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â• 50%)"], delta="‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â• 50%")
            col_b3.metric("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏π‡∏á (‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô/‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå)", bloom_stats["‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏π‡∏á (‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô/‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå) (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â• 10%)"], delta="‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â• 10%")
            
            st.markdown(f"**‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ:** {bloom_stats['‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ']}")
            
            
            # --- ‡∏™‡∏£‡πâ‡∏≤‡∏á Pie Chart ‡πÅ‡∏•‡∏∞ ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ ---
            st.markdown("---")
            st.subheader("üìà ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom‚Äôs Taxonomy")
            
            col_chart, col_table = st.columns([1, 1.2]) 

            # 1. Pie Chart 
            with col_chart:
                bloom_counts = bloom_stats['raw_counts']
                # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Pie Chart (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° Unknown)
                chart_data_raw = {
                    '‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom': list(bloom_counts.keys())[:-1],
                    '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠': list(bloom_counts.values())[:-1],
                    '‡∏™‡∏µ': [get_bloom_color(level) for level in list(bloom_counts.keys())[:-1]]
                }
                chart_df = pd.DataFrame(chart_data_raw)
                
                if not chart_df.empty and chart_df['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠'].sum() > 0:
                    base = alt.Chart(chart_df).encode(
                        theta=alt.Theta("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠", stack=True)
                    )
                    
                    pie = base.mark_arc(outerRadius=120).encode(
                        color=alt.Color("‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom", scale=alt.Scale(domain=chart_df['‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom'].tolist(), range=chart_df['‡∏™‡∏µ'].tolist())),
                        order=alt.Order("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠", sort="descending"),
                        tooltip=["‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠"]
                    )
                    
                    st.altair_chart(pie, use_container_width=True)
                else:
                    st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom ‡πÑ‡∏î‡πâ")
            
            # 2. ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û/‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom
            with col_table:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏£‡∏∏‡∏õ
                summary_table_data = []
                for level, count in bloom_stats['raw_counts'].items():
                    if level == 'Unknown': continue 
                    
                    level_items = [a for a in all_analysis if level.lower() in a.get('bloom_level', '').lower()]
                    good_count = sum(1 for a in level_items if a.get('is_good_question') is True)
                    
                    percent_text = f"{round((count / valid_total) * 100, 1) if valid_total > 0 else 0}%"
                    
                    summary_table_data.append({
                        '‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom': level,
                        '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠': count,
                        '‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô': percent_text,
                        '‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ': good_count,
                        '‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á': count - good_count
                    })
                
                summary_table_df = pd.DataFrame(summary_table_data)
                
                st.markdown("**‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom**")
                st.dataframe(
                    summary_table_df, 
                    hide_index=True, 
                    use_container_width=True,
                    column_config={
                        '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠': st.column_config.NumberColumn(format="%d ‡∏Ç‡πâ‡∏≠"),
                        '‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ': st.column_config.NumberColumn(format="%d ‡∏Ç‡πâ‡∏≠"),
                        '‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á': st.column_config.NumberColumn(format="%d ‡∏Ç‡πâ‡∏≠"),
                    }
                )

        # --- Tab: Details ---
        with tab_details:
            st.subheader("üìù ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠")
            
            # 1. ‡πÅ‡∏™‡∏î‡∏á DataFrame ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡πà‡∏≠‡∏ô
            st.dataframe(
                df[[
                    '‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà', '‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö', '‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î', 
                    '‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£', '‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö', '‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠', 
                    '‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞'
                ]],
                column_config={
                    "‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö": st.column_config.Column("‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö", width="small"),
                    "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î": st.column_config.Column("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î", width="small"),
                    "‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠": st.column_config.Column("‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠", width="medium"),
                },
                use_container_width=True,
                hide_index=True
            )
            
            # 2. Loop ‡∏™‡∏£‡πâ‡∏≤‡∏á expander ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ç‡πâ‡∏≠
            st.markdown("---")
            st.markdown("### üîé ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå (10 Fields) ‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠")
            
            for q_index, item in enumerate(all_analysis):
                quality_status = "‚úÖ ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ" if item.get('is_good_question') is True and item.get('bloom_level') != "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ" else "‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á/‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß"
                expander_title = f"**‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà {q_index+1}** | {quality_status} | ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î: **{item.get('bloom_level', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}**"
                
                # ‡πÉ‡∏ä‡πâ st.expander ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
                with st.expander(expander_title):
                    
                    st.markdown(f"**‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏ï‡πá‡∏°:**")
                    st.code(item.get('question_text', 'N/A'), language='markdown')
                    
                    st.markdown("---")

                    # ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏ä‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏™‡∏µ‡∏™‡∏±‡∏ô‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏° 
                    bloom_color = get_bloom_color(item.get('bloom_level', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'))
                    text_color = get_text_color_for_bloom(item.get('bloom_level', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'))
                    
                    col_det1, col_det2, col_det3 = st.columns([1, 1, 1]) 

                    with col_det1:
                        # ‡πÅ‡∏™‡∏î‡∏á Bloom Level
                        st.markdown(
                            f"""
                            <div style='background-color:{bloom_color}; color:{text_color}; padding: 10px; border-radius: 5px; text-align: center; margin-bottom: 10px;'>
                                <strong>üí° ‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom:</strong> {item.get('bloom_level', 'N/A')}
                            </div>
                            """, unsafe_allow_html=True
                        )
                    
                    with col_det2:
                         # ‡πÅ‡∏™‡∏î‡∏á Difficulty (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏™‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)
                        difficulty_level = item.get('difficulty', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
                        difficulty_color = {"‡∏á‡πà‡∏≤‡∏¢": "#008000", "‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á": "#FFA500", "‡∏¢‡∏≤‡∏Å": "#FF4500"}.get(difficulty_level, "#808080")
                        
                        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ï‡∏≤‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á
                        if difficulty_level in ["‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á"]: 
                            difficulty_text_color = "white" 
                        else:
                            difficulty_text_color = "white"
                        
                        st.markdown(
                            f"""
                            <div style='background-color:{difficulty_color}; color:{difficulty_text_color}; padding: 10px; border-radius: 5px; text-align: center; margin-bottom: 10px;'>
                                <strong>‚öñÔ∏è ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å:</strong> {difficulty_level}
                            </div>
                            """, unsafe_allow_html=True
                        )

                    with col_det3:
                        # ‡πÅ‡∏™‡∏î‡∏á Correct Option
                        st.markdown(
                            f"""
                            <div style='background-color:#0077B6; color:white; padding: 10px; border-radius: 5px; text-align: center; margin-bottom: 10px;'>
                                <strong>‚úÖ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:</strong> {item.get('correct_option', 'N/A')}
                            </div>
                            """, unsafe_allow_html=True
                        )

                    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å 
                    st.markdown(f"**üìö ‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£:** `{item.get('curriculum_standard', 'N/A')}`")
                    st.markdown(f"**üß† ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom/‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û:** {item.get('reasoning', 'N/A')}")
                    
                    st.divider()
                    st.subheader("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏•‡∏ß‡∏á")
                    st.markdown(f"**‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å:** {item.get('correct_option_analysis', 'N/A')}")
                    st.markdown(f"**‚ùå ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏•‡∏ß‡∏á (Distractors):** {item.get('distractor_analysis', 'N/A')}")
                    st.markdown(f"**üí° ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏ß‡∏•‡∏ß‡∏á‡∏î‡∏µ:** {item.get('why_good_distractor', 'N/A')}")
                    
                    st.warning(f"**üîß ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á:** {item.get('improvement_suggestion', 'N/A')}")
                
                st.divider() 


        # --- Tab: Raw JSON ---
        # (‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ)


if __name__ == "__main__":
    run_app()