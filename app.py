import os
import sys
import subprocess
import json
import re
import io
import time
import pandas as pd
from dotenv import load_dotenv
import streamlit as st
from PyPDF2 import PdfReader 
import google.generativeai as genai
from google.generativeai import types
from google.generativeai.types import GenerationConfig 
from typing import Dict, Any, Tuple
import altair as alt 


# --- 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î Environment ---
load_dotenv()
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', '').strip()

# ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ 
GEMINI_BATCH_MODEL_NAME = "gemini-2.5-flash" 

GEMINI_AVAILABLE = False
try:
    if GEMINI_API_KEY and len(GEMINI_API_KEY) > 30:
        genai.configure(api_key=GEMINI_API_KEY)
        GEMINI_AVAILABLE = True
except Exception:
    GEMINI_AVAILABLE = False


# Initialize session states
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'last_uploaded_file_name' not in st.session_state:
    st.session_state.last_uploaded_file_name = None
if 'question_texts' not in st.session_state:
    st.session_state.question_texts = None
if 'language' not in st.session_state:
    st.session_state.language = 'th'  # Default to Thai
if 'custom_prompt' not in st.session_state:
    st.session_state.custom_prompt = ""  # Custom prompt (empty = use default)

# --- Translation Dictionary ---
TRANSLATIONS = {
    'th': {
        # Header
        'app_title': 'üöÄ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö',
        'app_subtitle': '‚ú® ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢ <strong style="color: #667eea;">Gemini AI</strong> ‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡πÅ‡∏Å‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡∏Ø ‡πÅ‡∏•‡∏∞ <strong style="color: #764ba2;">Bloom\'s Taxonomy</strong>',
        
        # Sidebar
        'sidebar_title': '‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ & ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ AI',
        'ai_connected': '‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ AI ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à',
        'ai_not_connected': '‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key (GEMINI_API_KEY) - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô `.env`',
        'model_used': '**‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô**',
        'batch_analysis': 'Batch Analysis',
        'tips_title': 'üí° ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö',
        'tip_1': '- ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå **PDF** ‡∏´‡∏£‡∏∑‡∏≠ **TXT**',
        'tip_2': '- ‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ **‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠** (‡πÄ‡∏ä‡πà‡∏ô 1., 2.) ‡πÅ‡∏•‡∏∞ **‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å** (‡πÄ‡∏ä‡πà‡∏ô ‡∏Å., ‡∏Ç.)',
        'api_warning': '‡πÇ‡∏õ‡∏£‡∏î‡∏ó‡∏£‡∏≤‡∏ö: ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GEMINI_API_KEY ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå',
        
        # Custom Prompt
        'custom_prompt_title': 'üìù Custom Prompt (‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö)',
        'custom_prompt_label': '‡∏Å‡∏£‡∏≠‡∏Å Prompt ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÅ‡∏ó‡∏ô Prompt.txt:',
        'custom_prompt_placeholder': '‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ Prompt ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Prompt.txt...\n\n‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏Å Prompt ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡πÄ‡∏ä‡πà‡∏ô:\n\n‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ô‡∏µ‡πâ‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å Bloom\'s Taxonomy ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û...',
        'custom_prompt_active': '‚ú® ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ Custom Prompt',
        'custom_prompt_default': 'üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ Prompt ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå',
        
        # Step 1
        'step1_title': '1Ô∏è‚É£ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö (Batch Analysis)',
        'file_uploader_label': 'üìÅ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **(.PDF ‡∏´‡∏£‡∏∑‡∏≠ .TXT)**',
        'reading_file': '‚è≥ **‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö:**',
        'from_file': '‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå',
        'extracting': '‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°...',
        'no_questions_found': '‚ùå **‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö** ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå (‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠/‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ)',
        'file_tip': 'üí° **‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå:** ‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ **‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠** ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (‡πÄ‡∏ä‡πà‡∏ô 1., 2., 3.) ‡πÅ‡∏•‡∏∞‡∏°‡∏µ **‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å** (‡πÄ‡∏ä‡πà‡∏ô ‡∏Å., ‡∏Ç., ‡∏Ñ., ‡∏á.)',
        'file_read_error': '‚ùå **‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå:**',
        'extracted_questions': '‚úÖ ‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß **{count} ‡∏Ç‡πâ‡∏≠** ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå `{filename}`',
        
        # Step 2
        'step2_title': '2Ô∏è‚É£ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô üöÄ',
        'start_analysis_btn': 'üöÄ **‡∏Å‡∏î‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ AI**',
        'api_not_ready': 'Key ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤',
        'starting_analysis': 'üöÄ **‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ AI...**',
        'preparing_analysis': '‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö {count} ‡∏Ç‡πâ‡∏≠ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ `{model}`',
        'analyzing_question': 'ü§ñ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà {num}...',
        'analysis_progress': '‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö {current}/{total} ‡∏Ç‡πâ‡∏≠...',
        'analysis_complete': 'üéâ **‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!**',
        
        # Step 3 - Results
        'step3_title': '3Ô∏è‚É£ ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö üìù',
        'tab_summary': 'üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô & ‡πÄ‡∏Å‡∏ì‡∏ë‡πå Bloom',
        'tab_details': 'üìù ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠',
        'summary_title': 'üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö',
        'good_questions': '‚úÖ ‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ',
        'needs_improvement': '‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á',
        'total_questions': 'üìù ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î',
        'analyzed_success': 'ü§ñ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à',
        'bloom_criteria_title': 'üí° ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î (Bloom)',
        'bloom_low': '‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏ï‡πà‡∏≥ (‡∏à‡∏≥/‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à)',
        'bloom_mid': '‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏Å‡∏•‡∏≤‡∏á (‡πÉ‡∏ä‡πâ/‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå)',
        'bloom_high': '‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏π‡∏á (‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô/‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå)',
        'target': '‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢',
        'unidentified_bloom': '**‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ:**',
        'bloom_distribution': 'üìà ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom\'s Taxonomy',
        'bloom_table_title': '**‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom**',
        'details_title': 'üìù ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠',
        'click_detail': '### üîé ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå (10 Fields) ‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠',
        'question_num': '‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà',
        'quality': '‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö',
        'bloom_level': '‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î',
        'curriculum': '‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£',
        'answer': '‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö',
        'reasoning': '‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠',
        'suggestion': '‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞',
        'full_question': '**‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏ï‡πá‡∏°:**',
        'good': '‚úÖ ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ',
        'improve': '‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á/‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß',
        'difficulty': '‚öñÔ∏è ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å:',
        'correct_answer': '‚úÖ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:',
        'curriculum_indicator': '**üìö ‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£:**',
        'bloom_reason': '**üß† ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom/‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û:**',
        'answer_analysis_title': '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏•‡∏ß‡∏á',
        'correct_analysis': '**‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å:**',
        'distractor_analysis': '**‚ùå ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏•‡∏ß‡∏á (Distractors):**',
        'why_good_distractor': '**üí° ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏ß‡∏•‡∏ß‡∏á‡∏î‡∏µ:**',
        'improvement_suggestion': '**üîß ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á:**',
        
        # Quota Warning
        'quota_warning': '‚ö†Ô∏è **‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î Free Tier:** 20 requests/‡∏ß‡∏±‡∏ô ‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠ 24 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô',
        
        # Language
        'language_btn': 'üåê English',
    },
    'en': {
        # Header
        'app_title': 'üöÄ Exam Quality Analysis Tool',
        'app_subtitle': '‚ú® Automatic exam analysis with <strong style="color: #667eea;">Gemini AI</strong> based on Core Curriculum and <strong style="color: #764ba2;">Bloom\'s Taxonomy</strong>',
        
        # Sidebar
        'sidebar_title': '‚öôÔ∏è Settings & AI Status',
        'ai_connected': '‚úÖ AI Connected Successfully',
        'ai_not_connected': '‚ùå API Key not found (GEMINI_API_KEY) - Please set in `.env`',
        'model_used': '**Model Used**',
        'batch_analysis': 'Batch Analysis',
        'tips_title': 'üí° Tips',
        'tip_1': '- Use **PDF** or **TXT** files',
        'tip_2': '- Questions should have **numbers** (e.g., 1., 2.) and **choices** (e.g., A., B.)',
        'api_warning': 'Note: You must set GEMINI_API_KEY in .env file to use the analysis feature',
        
        # Custom Prompt
        'custom_prompt_title': 'üìù Custom Prompt (Optional)',
        'custom_prompt_label': 'Enter custom prompt to use instead of Prompt.txt:',
        'custom_prompt_placeholder': 'Leave empty to use default Prompt.txt...\n\nOr enter your custom prompt here, e.g.:\n\nAnalyze this exam question according to Bloom\'s Taxonomy and rate its quality...',
        'custom_prompt_active': '‚ú® Using Custom Prompt',
        'custom_prompt_default': 'üìÑ Using Default Prompt File',
        
        # Step 1
        'step1_title': '1Ô∏è‚É£ Upload Exam File (Batch Analysis)',
        'file_uploader_label': 'üìÅ Select exam file **(.PDF or .TXT)**',
        'reading_file': '‚è≥ **Reading and extracting questions:**',
        'from_file': 'from file',
        'extracting': 'Extracting text...',
        'no_questions_found': '‚ùå **No questions found** Please check the file format (no question numbers/choices or format too complex)',
        'file_tip': 'üí° **File preparation tip:** File should have clear **question numbers** (e.g., 1., 2., 3.) and **choices** (e.g., A., B., C., D.)',
        'file_read_error': '‚ùå **Error reading file:**',
        'extracted_questions': '‚úÖ Extracted **{count} questions** from file `{filename}`',
        
        # Step 2
        'step2_title': '2Ô∏è‚É£ Start Analysis & Generate Report üöÄ',
        'start_analysis_btn': 'üöÄ **Click here to start AI analysis**',
        'api_not_ready': 'API Key not ready. Please check settings',
        'starting_analysis': 'üöÄ **Starting AI analysis...**',
        'preparing_analysis': '‚è≥ Preparing to analyze {count} questions using `{model}`',
        'analyzing_question': 'ü§ñ Analyzing question {num}...',
        'analysis_progress': 'Analyzing question {current}/{total}...',
        'analysis_complete': 'üéâ **Analysis Complete!**',
        
        # Step 3 - Results
        'step3_title': '3Ô∏è‚É£ Exam Analysis Results üìù',
        'tab_summary': 'üìä Summary & Bloom Criteria',
        'tab_details': 'üìù Question Details',
        'summary_title': 'üìä Overall Exam Quality Summary',
        'good_questions': '‚úÖ Good Quality Questions',
        'needs_improvement': '‚ö†Ô∏è Needs Improvement',
        'total_questions': 'üìù Total Questions',
        'analyzed_success': 'ü§ñ Successfully Analyzed',
        'bloom_criteria_title': 'üí° Bloom\'s Taxonomy Distribution Criteria',
        'bloom_low': 'Lower Order (Remember/Understand)',
        'bloom_mid': 'Middle Order (Apply/Analyze)',
        'bloom_high': 'Higher Order (Evaluate/Create)',
        'target': 'Target',
        'unidentified_bloom': '**Questions with unidentified Bloom level:**',
        'bloom_distribution': 'üìà Bloom\'s Taxonomy Distribution',
        'bloom_table_title': '**Summary Table: Questions by Bloom Level**',
        'details_title': 'üìù Detailed Analysis per Question',
        'click_detail': '### üîé Click to view detailed analysis (10 Fields) per question',
        'question_num': 'Q#',
        'quality': 'Quality',
        'bloom_level': 'Bloom Level',
        'curriculum': 'Curriculum Standard',
        'answer': 'Answer',
        'reasoning': 'Brief Reasoning',
        'suggestion': 'Suggestion',
        'full_question': '**Full Question:**',
        'good': '‚úÖ Good',
        'improve': '‚ùå Needs Improvement/Failed',
        'difficulty': '‚öñÔ∏è Difficulty:',
        'correct_answer': '‚úÖ Answer:',
        'curriculum_indicator': '**üìö Curriculum Indicator:**',
        'bloom_reason': '**üß† Bloom Level/Quality Reasoning:**',
        'answer_analysis_title': 'Answer & Distractor Analysis',
        'correct_analysis': '**‚úÖ Correct Answer Analysis:**',
        'distractor_analysis': '**‚ùå Distractor Analysis:**',
        'why_good_distractor': '**üí° Why Good Distractors:**',
        'improvement_suggestion': '**üîß Improvement Suggestion:**',
        
        # Quota Warning
        'quota_warning': '‚ö†Ô∏è **Free Tier Limit:** 20 requests/day. If exceeded, please wait 24 hours or upgrade your plan.',
        
        # Language
        'language_btn': 'üåê ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢',
    }
}

def t(key):
    """Get translation for current language"""
    lang = st.session_state.get('language', 'th')
    return TRANSLATIONS.get(lang, TRANSLATIONS['th']).get(key, key)


# --- 2. ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Prompt Template ---
def load_prompts() -> Tuple[str, str]:
    """‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ Prompt Template ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå 'Prompt.txt' ‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡πÄ‡∏õ‡πá‡∏ô System/Chat"""
    prompt_path = os.path.join(os.path.dirname(__file__), 'Prompt.txt')
    try:
        with open(prompt_path, 'r', encoding='utf-8') as f:
            full_content = f.read()
            
            # 1. System Instruction
            system_match = full_content.split("# --- END_SYSTEM_INSTRUCTION_ANALYSIS_MODE ---")[0]
            SYSTEM_INSTRUCTION_PROMPT = system_match.strip() if system_match else "You are a test expert for Thai curriculum. Analyze the question and return a JSON object."
            
            # 2. Few-Shot Template 
            chat_match = full_content.split("# --- CHAT_PROMPT ---")
            
            if len(chat_match) > 1:
                # ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô Prompt Template ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                template_content = chat_match[1].split("# --- CHAT_PROMPT_END ---")[0].strip()
                # ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏° {user_query} ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡πâ‡∏≤‡∏¢
                FEW_SHOT_PROMPT_TEMPLATE = template_content + "\n{user_query}"
            else:
                FEW_SHOT_PROMPT_TEMPLATE = "Analyze the following question/text and return the JSON object: {user_query}"

            return SYSTEM_INSTRUCTION_PROMPT, FEW_SHOT_PROMPT_TEMPLATE
    except FileNotFoundError:
        return (
            "# Error: Prompt file not found. Fallback to default instruction.", 
            "Analyze the following question/text and return the JSON object: {user_query}"
        )

SYSTEM_INSTRUCTION_PROMPT, FEW_SHOT_PROMPT_TEMPLATE = load_prompts()


# --- 3. Helper Functions ---

BLOOM_COLORS = {
    "REMEMBER": "#6495ED",  
    "UNDERSTAND": "#40E0D0",
    "APPLY": "#50C878",     
    "ANALYZE": "#8FBC8F",   
    "EVALUATE": "#ADFF2F",  
    "CREATE": "#FFD700",    
    "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏": "#A9A9A9",
    "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ": "#A9A9A9"
}

def get_bloom_color(level):
    """‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡∏£‡∏´‡∏±‡∏™‡∏™‡∏µ Hex ‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom's Taxonomy"""
    if not level:
        return BLOOM_COLORS['‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏']
    
    level_upper = level.strip().upper()
    for key, color in BLOOM_COLORS.items():
        if key in level_upper:
            return color
    return BLOOM_COLORS['‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'] # Fallback

def get_text_color_for_bloom(level):
    """‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏î‡∏Å‡∏±‡∏ö‡∏™‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô)"""
    level_upper = level.strip().upper()
    if level_upper in ['EVALUATE', 'CREATE']: # ‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á/‡∏ó‡∏≠‡∏á/‡∏™‡∏ß‡πà‡∏≤‡∏á ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏™‡∏µ‡∏î‡∏≥
        return 'black' 
    return 'white' # ‡∏™‡∏µ‡πÄ‡∏Ç‡πâ‡∏°‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß


def extract_text_from_pdf(pdf_reader):
    """‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ PdfReader"""
    text = ""
    for page in pdf_reader.pages:
        try:
            page_text = page.get_text() if hasattr(page, 'get_text') else page.extract_text()
            text += (page_text or "") + "\n"
        except Exception:
            text += "\n"
    return text.strip()

def clean_and_normalize(text):
    """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏•‡∏Ç‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡∏≠‡∏≤‡∏£‡∏ö‡∏¥‡∏Å"""
    if not text: return ""
    # 1. ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏•‡∏Ç‡πÑ‡∏ó‡∏¢
    thai_digits = "‡πê‡πë‡πí‡πì‡πî‡πï‡πñ‡πó‡πò‡πô"
    for i, digit in enumerate(thai_digits):
        text = text.replace(digit, str(i))
    
    # 2. ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á
    text = re.sub(r'[ \t]+', ' ', text) 
    text = text.replace('\r', '')
    
    # 3. ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ö‡∏à‡∏∏‡∏î (‡πÄ‡∏ä‡πà‡∏ô ‡∏Å . -> ‡∏Å.)
    text = re.sub(r'([‡∏Å-‡∏áA-D])\s*\.', r'\1.', text)
    
    # 4. ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ö‡∏à‡∏∏‡∏î (‡πÄ‡∏ä‡πà‡∏ô 1 . -> 1.)
    text = re.sub(r'(\d+)\s*\.', r'\1.', text)
    
    # 5. ‡∏•‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
    text = re.sub(r'\n{2,}', '\n', text)
    
    lines = [line.strip() for line in text.split('\n')]
    return '\n'.join(lines)

def extract_questions(raw_text):
    """
    ‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠ (‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà 1-99 ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡∏Å. ‡∏Ç.)
    """
    # 1. ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    # ‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô "‡πÄ‡∏â‡∏•‡∏¢" ‡∏ó‡∏¥‡πâ‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏≠‡∏á
    text = re.split(r"={10,}\s*‡πÄ‡∏â‡∏•‡∏¢\s*={10,}", raw_text, flags=re.DOTALL | re.IGNORECASE)[0]
    cleaned_text = clean_and_normalize(text)
    
    # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Regex ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠ (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÅ‡∏Ñ‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç 1-99)
    question_prefix = r'(?:[1-9]\d?\.|\([1-9]\d?\))\s*' 
    
    # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Regex ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (Thai/English)
    option_marker = r'(?:‡∏Å\.\s*|A\.\s*)'
    
    # 4. ‡∏£‡∏ß‡∏° Regex: ‡∏à‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠ (1-99) ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡∏Å./A. ‡∏ï‡∏≤‡∏°‡∏°‡∏≤
    pattern = r'(\s*' + question_prefix + r'.*?' + option_marker + r'.*?)(?=\s*' + question_prefix + r'|\s*$)'
    
    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    matches = re.findall(pattern, cleaned_text, flags=re.DOTALL | re.IGNORECASE)
    
    questions = []
    
    # 5. ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
    for m in matches:
        q = m.strip()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡∏Å-‡∏á ‡∏´‡∏£‡∏∑‡∏≠ A-D ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏ï‡∏±‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        option_count_thai = len(re.findall(r'[‡∏Å-‡∏á]\s*\.', q))
        option_count_eng = len(re.findall(r'[A-D]\s*\.', q))
        
        # ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç: ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏ï‡∏±‡∏ß
        if option_count_thai >= 2 or option_count_eng >= 2:
            # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡πâ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà
            q_formatted = re.sub(r'(\s*[‡∏Å‡∏Ç‡∏Ñ‡∏á]\s*\.)', r'\n\1', q)
            q_formatted = re.sub(r'(\s*[A-D]\s*\.)', r'\n\1', q_formatted)
            questions.append(q_formatted.strip())
        
    return questions


def analyze_with_gemini(question_text, question_id=1):
    """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Gemini API ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö (10 Fields Logic)"""
    if not GEMINI_AVAILABLE:
        return {
            "bloom_level": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "reasoning": "‡πÑ‡∏°‡πà‡∏û‡∏ö API Key",
            "difficulty": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "curriculum_standard": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏",
            "correct_option": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "correct_option_analysis": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ AI",
            "distractor_analysis": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ AI", "why_good_distractor": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ AI",
            "is_good_question": False, "improvement_suggestion": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ: ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key"
        } 

    # Check for custom prompt
    custom_prompt = st.session_state.get('custom_prompt', '').strip()
    
    if custom_prompt:
        # Use custom prompt as system instruction
        system_instruction = custom_prompt
        prompt_template = "{user_query}"  # Simple template for custom prompt
    else:
        # Use default prompts from Prompt.txt
        system_instruction = SYSTEM_INSTRUCTION_PROMPT
        prompt_template = FEW_SHOT_PROMPT_TEMPLATE

    model = genai.GenerativeModel(
        GEMINI_BATCH_MODEL_NAME, 
        system_instruction=system_instruction
    )
    
    question_text_formatted = f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà {question_id}:\n{question_text}"
    
    # ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Prompt ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    full_prompt = prompt_template.format(user_query=question_text_formatted) 
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î JSON Schema (10 Fields)
    json_schema = {
        "type": "object",
        "properties": {
            "bloom_level": {"type": "string"},
            "reasoning": {"type": "string"},
            "difficulty": {"type": "string"},
            "curriculum_standard": {"type": "string"},
            "correct_option": {"type": "string"},
            "correct_option_analysis": {"type": "string"},
            "distractor_analysis": {"type": "string"},
            "why_good_distractor": {"type": "string"},
            "is_good_question": {"type": "boolean"},
            "improvement_suggestion": {"type": "string"}
        },
        "required": [
            "bloom_level", "reasoning", "difficulty", "curriculum_standard",
            "correct_option", "correct_option_analysis", "distractor_analysis",
            "why_good_distractor", "is_good_question", "improvement_suggestion"
        ]
    }

    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Config (‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö JSON ‡πÅ‡∏•‡∏∞‡∏•‡∏î Temperature)
    config = GenerationConfig( 
        response_mime_type="application/json", 
        response_schema=json_schema, 
        temperature=0.0
    )
    
    last_error_message = ""

    for attempt in range(3):
        delay = 2 ** attempt
        if attempt > 0:
            time.sleep(delay)
            
        try:
            response = model.generate_content(
                full_prompt, 
                generation_config=config, 
            )
            raw_text = response.text.strip()
        
            # Hardened JSON Cleaning/Extraction
            cleaned_json = re.sub(r'^```(?:json)?\s*|```$', '', raw_text, flags=re.MULTILINE | re.DOTALL).strip()
            start_brace = cleaned_json.find('{')
            end_brace = cleaned_json.rfind('}')
            
            if start_brace != -1 and end_brace != -1 and end_brace > start_brace:
                cleaned_json = cleaned_json[start_brace:end_brace+1].strip()
            else:
                raise ValueError("Could not find valid JSON structure (missing { or }).") 
            
            # ‡πÇ‡∏´‡∏•‡∏î JSON
            analysis = json.loads(cleaned_json)
            
            # Data sanitation and Key validation
            required_keys = [
                "bloom_level", "reasoning", "difficulty", "curriculum_standard",
                "correct_option", "correct_option_analysis", "distractor_analysis",
                "why_good_distractor", "is_good_question", "improvement_suggestion"
            ]
            
            def safe_str(val): return str(val).strip() if val is not None else "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
            def safe_bool(val):
                if isinstance(val, str): 
                    return val.lower().strip() == 'true'
                if val in (True, False): return val
                return False

            final_analysis = {}
            for key in required_keys:
                raw_val = analysis.get(key)
                if key == "is_good_question":
                    final_analysis[key] = safe_bool(raw_val)
                else:
                    final_analysis[key] = safe_str(raw_val if raw_val is not None else "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
                
                if key not in analysis:
                    raise KeyError(f"JSON Output is missing required key: {key}")

            return final_analysis

        except (json.JSONDecodeError, ValueError, KeyError) as e:
            last_error_message = f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• JSON/Key: {type(e).__name__}: {str(e)}"
            continue # ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà (Retry)
            
        except Exception as e:
            error_str = str(e)
            # Handle Rate Limit / Quota Exceeded (429 Error)
            if "429" in error_str or "quota" in error_str.lower() or "ResourceExhausted" in error_str:
                # Extract retry delay if available
                retry_delay = 30  # Default 30 seconds
                import re as regex_module
                delay_match = regex_module.search(r'retry.*?(\d+)', error_str.lower())
                if delay_match:
                    retry_delay = int(delay_match.group(1)) + 5  # Add 5 seconds buffer
                
                last_error_message = f"‚è≥ Rate Limit: ‡∏£‡∏≠ {retry_delay} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà..."
                
                # Auto-retry after waiting
                if attempt < 2:  # Only wait and retry if not last attempt
                    time.sleep(retry_delay)
                    continue
                else:
                    last_error_message = f"‚ùå Quota Exceeded: ‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤ API ‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡πâ‡∏ß ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠ 24 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"
                    break
            else:
                last_error_message = f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {type(e).__name__}: {str(e)}"
                continue

    # Fallback ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢: ‡∏´‡∏≤‡∏Å AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
    return {
        "bloom_level": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ", "reasoning": "AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß",
        "difficulty": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÑ‡∏î‡πâ", "curriculum_standard": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ",
        "correct_option": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "correct_option_analysis": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏",
        "distractor_analysis": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "why_good_distractor": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏",
        "is_good_question": False, 
        "improvement_suggestion": f"**‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå**: {last_error_message}"
    }


def check_bloom_criteria(analysis_results):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà."""
    total = len(analysis_results)
    if total == 0: 
        return {"pass": False, "reason": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö", "percentages": {}, "raw_counts": {}, "valid_total": 0} 

    # Standardized Level Names for grouping
    LEVEL_GROUPS = {
        "Remember": 0, "Understand": 0, "Apply": 0, 
        "Analyze": 0, "Evaluate": 0, "Create": 0, "Unknown": 0
    }
    
    for item in analysis_results:
        level = str(item.get("bloom_level", "")).strip().lower()
        if "remember" in level: LEVEL_GROUPS["Remember"] += 1
        elif "understand" in level: LEVEL_GROUPS["Understand"] += 1
        elif "apply" in level: LEVEL_GROUPS["Apply"] += 1
        elif "analyze" in level: LEVEL_GROUPS["Analyze"] += 1
        elif "evaluate" in level: LEVEL_GROUPS["Evaluate"] += 1
        elif "create" in level: LEVEL_GROUPS["Create"] += 1
        else: LEVEL_GROUPS["Unknown"] += 1

    apply_analyze_count = LEVEL_GROUPS["Apply"] + LEVEL_GROUPS["Analyze"]
    remember_understand_count = LEVEL_GROUPS["Remember"] + LEVEL_GROUPS["Understand"]
    evaluate_create_count = LEVEL_GROUPS["Evaluate"] + LEVEL_GROUPS["Create"]
    valid_total = total - LEVEL_GROUPS["Unknown"] # ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom ‡πÑ‡∏î‡πâ

    if valid_total == 0:
        return {"pass": False, "reason": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢", "percentages": {}, "raw_counts": LEVEL_GROUPS, "valid_total": 0} 
        
    percent = {
        "Remember/Understand": round((remember_understand_count / valid_total) * 100, 1) if valid_total > 0 else 0,
        "Apply/Analyze": round((apply_analyze_count / valid_total) * 100, 1) if valid_total > 0 else 0,
        "Evaluate/Create": round((evaluate_create_count / valid_total) * 100, 1) if valid_total > 0 else 0
    }

    # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏ï‡πà‡∏≥ ‚â§ 40%, ‡∏Å‡∏•‡∏≤‡∏á ‚â• 50%, ‡∏™‡∏π‡∏á ‚â• 10%)
    pass_r_u = percent["Remember/Understand"] <= 40
    pass_a_a = percent["Apply/Analyze"] >= 50
    pass_e_c = percent["Evaluate/Create"] >= 10
    passed = pass_r_u and pass_a_a and pass_e_c

    reason = "‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏ú‡πà‡∏≤‡∏ô** ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î (Bloom)" if passed else "‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô** ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î (Bloom)"

    return {
        "pass": passed,
        "reason": reason,
        "percentages": percent,
        "raw_counts": LEVEL_GROUPS,
        "valid_total": valid_total 
    }

def create_analysis_report(all_analysis, bloom_check):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞ DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•"""
    total_questions = len(all_analysis)
    
    failed_analysis = sum(1 for a in all_analysis if "QUOTA EXCEEDED" in a.get('improvement_suggestion', '') or "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå" in a.get('improvement_suggestion', ''))
    
    successfully_analyzed_questions = total_questions - failed_analysis
    good_questions = sum(1 for a in all_analysis if a.get('is_good_question') is True and a.get('bloom_level') != "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ")

    summary_data = {
        "‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°": {
            "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î": f"{total_questions} ‡∏Ç‡πâ‡∏≠",
            "‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à": f"{successfully_analyzed_questions} ‡∏Ç‡πâ‡∏≠",
            "‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏î‡∏µ** (‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)": f"{good_questions} ‡∏Ç‡πâ‡∏≠ ({round((good_questions/successfully_analyzed_questions)*100, 1) if successfully_analyzed_questions > 0 else 0}%)",
            "‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á**": f"{successfully_analyzed_questions - good_questions} ‡∏Ç‡πâ‡∏≠ ({round(((successfully_analyzed_questions - good_questions)/successfully_analyzed_questions)*100, 1) if successfully_analyzed_questions > 0 else 0}%)"
        },
        "‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î": {
            "‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°": bloom_check['reason'],
            "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏ï‡πà‡∏≥ (‡∏à‡∏≥/‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à) (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â§ 40%)": f"{bloom_check['percentages'].get('Remember/Understand', 0)}%",
            "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏Å‡∏•‡∏≤‡∏á (‡πÉ‡∏ä‡πâ/‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå) (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â• 50%)": f"{bloom_check['percentages'].get('Apply/Analyze', 0)}%", 
            "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏π‡∏á (‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô/‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå) (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â• 10%)": f"{bloom_check['percentages'].get('Evaluate/Create', 0)}%",
            "‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ": f"{bloom_check['raw_counts'].get('Unknown', 0)} ‡∏Ç‡πâ‡∏≠",
            "raw_counts": bloom_check['raw_counts'],
            "valid_total": bloom_check.get('valid_total', 0)
        }
    }
    
    df_data = []
    for i, item in enumerate(all_analysis):
        is_good = "‚úÖ ‡∏î‡∏µ" if item.get('is_good_question') is True and item.get('bloom_level') != "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ" else "‚ùå ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á/‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß"
        df_data.append({
            '‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà': i + 1,
            '‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö': is_good,
            '‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î': item.get('bloom_level', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
            '‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£': item.get('curriculum_standard', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
            '‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö': item.get('correct_option', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
            '‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠': item.get('reasoning', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•'),
            '‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞': item.get('improvement_suggestion', '‡πÑ‡∏°‡πà‡∏°‡∏µ'),
            '‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏ï‡πá‡∏°': item.get('question_text', '')
        })
    df = pd.DataFrame(df_data)
    return summary_data, df

# --- 4. Main App Function (UI) ---

def run_app():
    # üé® ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
    st.set_page_config(
        page_title="‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (Gemini AI)",
        page_icon="üìù", 
        layout="wide",
        initial_sidebar_state="auto", 
        menu_items=None
    )
    
    # üé® Custom CSS Theme - Premium Polished Design
    st.markdown("""
    <style>
    /* Import Google Fonts */
    @import url('https://fonts.googleapis.com/css2?family=Prompt:wght@300;400;500;600;700&display=swap');
    
    /* ===== GLOBAL STYLES ===== */
    .stApp {
        background: linear-gradient(180deg, #ffffff 0%, #f8fafc 100%);
        font-family: 'Prompt', sans-serif;
        min-height: 100vh;
    }
    
    /* Hide Streamlit branding */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* ===== SIDEBAR STYLES ===== */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #f8fafc 0%, #f1f5f9 100%);
        border-right: 1px solid #e2e8f0;
    }
    
    [data-testid="stSidebar"] .stMarkdown {
        color: #475569;
    }
    
    [data-testid="stSidebar"] h1, 
    [data-testid="stSidebar"] h2, 
    [data-testid="stSidebar"] h3 {
        color: #1e293b !important;
        font-weight: 600;
    }
    
    /* ===== MAIN CONTENT STYLES ===== */
    .main .block-container {
        padding: 2rem 1rem;
        max-width: 1100px;
    }
    
    /* Main content area */
    .main > div {
        background: #ffffff;
        border-radius: 20px;
        padding: 2rem;
        margin: 1rem;
    }
    
    /* Headers */
    h1 {
        background: linear-gradient(135deg, #6366f1 0%, #8b5cf6 50%, #a855f7 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        font-weight: 700 !important;
        font-size: 2.2rem !important;
        text-align: center;
        padding: 0.5rem 0;
    }
    
    h2 {
        color: #1e293b !important;
        font-weight: 600 !important;
        font-size: 1.4rem !important;
        padding-bottom: 0.75rem;
        margin-top: 1.5rem;
        border-bottom: 2px solid;
        border-image: linear-gradient(90deg, #6366f1, #a855f7, #e2e8f0) 1;
    }
    
    h3 {
        color: #334155 !important;
        font-weight: 600 !important;
    }
    
    /* Regular text */
    .stMarkdown, p, span, label {
        color: #475569 !important;
    }
    
    /* ===== CONTAINER & CARDS ===== */
    div[data-testid="stVerticalBlockBorderWrapper"] {
        background: #ffffff !important;
        border-radius: 16px !important;
        border: 1px solid #e2e8f0 !important;
        box-shadow: 0 4px 20px rgba(99, 102, 241, 0.08);
        transition: all 0.3s ease;
        overflow: hidden;
    }
    
    div[data-testid="stVerticalBlockBorderWrapper"]:hover {
        transform: translateY(-4px);
        box-shadow: 0 12px 40px rgba(99, 102, 241, 0.15);
        border-color: #c7d2fe !important;
    }
    
    /* ===== FILE UPLOADER ===== */
    [data-testid="stFileUploader"] {
        background: transparent;
    }
    
    [data-testid="stFileUploader"] section {
        background: linear-gradient(135deg, #f5f3ff 0%, #ede9fe 100%);
        border: 2px dashed #a5b4fc;
        border-radius: 16px;
        transition: all 0.3s ease;
        padding: 2rem;
    }
    
    [data-testid="stFileUploader"] section:hover {
        border-color: #6366f1;
        background: linear-gradient(135deg, #ede9fe 0%, #e0e7ff 100%);
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(99, 102, 241, 0.15);
    }
    
    /* ===== BUTTONS ===== */
    .stButton > button {
        background: linear-gradient(135deg, #6366f1 0%, #8b5cf6 100%);
        color: white !important;
        border: none;
        border-radius: 12px;
        padding: 0.8rem 1.8rem;
        font-weight: 600;
        font-size: 0.95rem;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(99, 102, 241, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-3px);
        box-shadow: 0 8px 30px rgba(99, 102, 241, 0.4);
        background: linear-gradient(135deg, #8b5cf6 0%, #a855f7 100%);
    }
    
    .stButton > button:active {
        transform: translateY(-1px);
    }
    
    /* Primary button */
    .stButton > button[kind="primary"] {
        background: linear-gradient(135deg, #6366f1 0%, #8b5cf6 100%);
        box-shadow: 0 4px 20px rgba(99, 102, 241, 0.35);
    }
    
    .stButton > button[kind="primary"]:hover {
        background: linear-gradient(135deg, #8b5cf6 0%, #a855f7 100%);
        box-shadow: 0 8px 35px rgba(139, 92, 246, 0.45);
    }
    
    /* ===== TEXT INPUT & TEXT AREA ===== */
    .stTextInput > div > div > input,
    .stTextArea > div > div > textarea {
        background: #ffffff !important;
        border: 2px solid #e2e8f0 !important;
        border-radius: 10px !important;
        color: #1e293b !important;
        transition: all 0.3s ease;
    }
    
    .stTextInput > div > div > input:focus,
    .stTextArea > div > div > textarea:focus {
        border-color: #6366f1 !important;
        box-shadow: 0 0 0 3px rgba(99, 102, 241, 0.15) !important;
    }
    
    .stTextInput > div > div > input::placeholder,
    .stTextArea > div > div > textarea::placeholder {
        color: #94a3b8 !important;
    }
    
    /* ===== METRICS ===== */
    [data-testid="stMetric"] {
        background: linear-gradient(135deg, #f5f3ff 0%, #ede9fe 100%);
        border-radius: 16px;
        padding: 1.25rem;
        border: 1px solid #e0e7ff;
        transition: all 0.3s ease;
    }
    
    [data-testid="stMetric"]:hover {
        transform: translateY(-4px);
        box-shadow: 0 10px 30px rgba(99, 102, 241, 0.12);
        border-color: #c7d2fe;
    }
    
    [data-testid="stMetric"] label {
        color: #6366f1 !important;
        font-weight: 500;
        font-size: 0.85rem;
    }
    
    [data-testid="stMetric"] [data-testid="stMetricValue"] {
        font-size: 2.2rem !important;
        font-weight: 700 !important;
        color: #1e293b !important;
    }
    
    [data-testid="stMetric"] [data-testid="stMetricDelta"] {
        color: #10b981 !important;
        font-weight: 600;
    }
    
    /* ===== TABS ===== */
    .stTabs [data-baseweb="tab-list"] {
        background: #f1f5f9;
        border-radius: 12px;
        padding: 0.35rem;
        gap: 0.35rem;
    }
    
    .stTabs [data-baseweb="tab"] {
        background: transparent;
        color: #64748b;
        border-radius: 10px;
        padding: 0.7rem 1.25rem;
        font-weight: 500;
        transition: all 0.2s ease;
    }
    
    .stTabs [data-baseweb="tab"]:hover {
        background: #e2e8f0;
        color: #1e293b;
    }
    
    .stTabs [aria-selected="true"] {
        background: #ffffff !important;
        color: #6366f1 !important;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
    }
    
    /* ===== EXPANDERS ===== */
    .streamlit-expanderHeader {
        background: #f8fafc;
        border-radius: 12px;
        border: 1px solid #e2e8f0;
        color: #1e293b !important;
        font-weight: 500;
        transition: all 0.2s ease;
    }
    
    .streamlit-expanderHeader:hover {
        background: #f1f5f9;
        border-color: #c7d2fe;
    }
    
    .streamlit-expanderContent {
        background: #ffffff;
        border-radius: 0 0 12px 12px;
        border: 1px solid #e2e8f0;
        border-top: none;
    }
    
    /* ===== DATAFRAMES ===== */
    [data-testid="stDataFrame"] {
        background: #ffffff;
        border-radius: 12px;
        overflow: hidden;
        border: 1px solid #e2e8f0;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.04);
    }
    
    /* ===== ALERTS ===== */
    .stSuccess {
        background: #f0fdf4 !important;
        border: 1px solid #86efac !important;
        border-radius: 12px;
        border-left: 4px solid #22c55e !important;
    }
    
    .stSuccess p, .stSuccess span {
        color: #166534 !important;
    }
    
    .stWarning {
        background: #fffbeb !important;
        border: 1px solid #fde68a !important;
        border-radius: 12px;
        border-left: 4px solid #f59e0b !important;
    }
    
    .stWarning p, .stWarning span {
        color: #92400e !important;
    }
    
    .stError {
        background: #fef2f2 !important;
        border: 1px solid #fecaca !important;
        border-radius: 12px;
        border-left: 4px solid #ef4444 !important;
    }
    
    .stError p, .stError span {
        color: #991b1b !important;
    }
    
    .stInfo {
        background: #eff6ff !important;
        border: 1px solid #bfdbfe !important;
        border-radius: 12px;
        border-left: 4px solid #6366f1 !important;
    }
    
    .stInfo p, .stInfo span {
        color: #1e3a8a !important;
    }
    
    /* ===== PROGRESS BAR ===== */
    .stProgress > div > div {
        background: linear-gradient(90deg, #6366f1, #8b5cf6, #a855f7);
        border-radius: 10px;
    }
    
    /* ===== STATUS ===== */
    [data-testid="stStatusWidget"] {
        background: #ffffff;
        border-radius: 12px;
        border: 1px solid #e2e8f0;
    }
    
    /* ===== DIVIDERS ===== */
    hr {
        border: none;
        height: 1px;
        background: linear-gradient(90deg, transparent, #c7d2fe, #e9d5ff, transparent);
        margin: 1.5rem 0;
    }
    
    /* ===== CODE BLOCKS ===== */
    .stCodeBlock {
        background: rgba(15, 23, 42, 0.95) !important;
        border-radius: 12px;
        border: 1px solid rgba(102, 126, 234, 0.3);
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
    }
    
    /* ===== CUSTOM SCROLLBAR ===== */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }
    
    ::-webkit-scrollbar-track {
        background: #f1f5f9;
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb {
        background: linear-gradient(180deg, #6366f1, #8b5cf6);
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: linear-gradient(180deg, #8b5cf6, #a855f7);
    }
    
    /* ===== SPECIAL EFFECTS ===== */
    .floating-card {
        animation: float 3s ease-in-out infinite;
    }
    
    @keyframes float {
        0%, 100% { transform: translateY(0); }
        50% { transform: translateY(-10px); }
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Language toggle function
    def toggle_language():
        if st.session_state.language == 'th':
            st.session_state.language = 'en'
        else:
            st.session_state.language = 'th'
    
    # Modern Minimal Header (Dynamic)
    st.markdown(f"""
    <div style="
        text-align: center; 
        padding: 1.5rem 1rem 2rem 1rem;
        margin-bottom: 0.5rem;
    ">
        <h1 style="
            font-size: 2.4rem;
            font-weight: 700;
            background: linear-gradient(135deg, #6366f1 0%, #8b5cf6 50%, #a855f7 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 0.75rem;
        ">
            {t('app_title')}
        </h1>
        <p style="
            color: #64748b;
            font-size: 1rem;
            max-width: 600px;
            margin: 0 auto;
            line-height: 1.6;
        ">
            {t('app_subtitle')}
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("<hr>", unsafe_allow_html=True) 

    
    with st.sidebar:
        # Language Toggle Button at top
        st.button(
            t('language_btn'), 
            on_click=toggle_language,
            use_container_width=True,
            key='lang_toggle'
        )
        st.markdown("---")
        
        st.header(t('sidebar_title'))
        
        if GEMINI_AVAILABLE:
            st.success(t('ai_connected'))
        else:
            st.error(t('ai_not_connected'))
        
        st.markdown(t('model_used'))
        st.info(f"{t('batch_analysis')}: `{GEMINI_BATCH_MODEL_NAME}`") 
        st.markdown("---")
        st.subheader(t('tips_title'))
        st.markdown(t('tip_1'))
        st.markdown(t('tip_2'))
        
        # Quota Warning
        st.markdown("---")
        st.warning(t('quota_warning'))

        if not GEMINI_AVAILABLE:
            st.error(t('api_warning'))

    # --- Custom Prompt Section (Main Content) ---
    st.markdown("---")
    with st.expander(t('custom_prompt_title'), expanded=False):
        st.markdown(f"**{t('custom_prompt_label')}**")
        custom_prompt_input = st.text_area(
            t('custom_prompt_label'),
            value=st.session_state.custom_prompt,
            height=150,
            placeholder=t('custom_prompt_placeholder'),
            key='custom_prompt_input',
            label_visibility="collapsed"
        )
        
        # Update session state
        if custom_prompt_input != st.session_state.custom_prompt:
            st.session_state.custom_prompt = custom_prompt_input
            st.session_state.analysis_results = None
        
        # Show status in columns
        col_status1, col_status2 = st.columns([1, 1])
        with col_status1:
            if st.session_state.custom_prompt.strip():
                st.success(t('custom_prompt_active'))
            else:
                st.info(t('custom_prompt_default'))

    # --- Step 1: Upload ---
    st.markdown("---")
    st.header(t('step1_title'))
    with st.container(border=True):
        st.markdown(f"**{t('file_uploader_label')}**")
        uploaded_file = st.file_uploader(
            t('file_uploader_label'), 
            type=['pdf', 'txt'], 
            accept_multiple_files=False, 
            key='file_uploader_widget', 
            label_visibility="collapsed"
        )
        st.caption(t('file_tip'))

        if uploaded_file is not None:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if uploaded_file.name != st.session_state.last_uploaded_file_name:
                st.session_state.analysis_results = None
                st.session_state.last_uploaded_file_name = uploaded_file.name
                st.session_state.question_texts = None
                
            if st.session_state.question_texts is None:
                file_extension = uploaded_file.name.split('.')[-1].lower()
                
                # Custom Loading UI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö
                status_container = st.empty()
                status_container.info(f"{t('reading_file')}\n\n{t('from_file')} **{uploaded_file.name}**...")
                
                with st.spinner(t('extracting')):
                    try:
                        if file_extension == 'pdf':
                            with io.BytesIO(uploaded_file.getvalue()) as open_pdf_file:
                                pdf_reader = PdfReader(open_pdf_file)
                                raw_text = extract_text_from_pdf(pdf_reader)
                        elif file_extension == 'txt':
                            raw_text = uploaded_file.getvalue().decode("utf-8")
                        
                        question_texts = extract_questions(raw_text)
                        st.session_state.question_texts = question_texts
                        
                        status_container.empty() # ‡∏•‡πâ‡∏≤‡∏á Custom Loading
                        
                        if not question_texts:
                            st.error(t('no_questions_found'))
                            st.info(t('file_tip'))
                            return 
                        
                    except Exception as e:
                        status_container.empty() # ‡∏•‡πâ‡∏≤‡∏á Custom Loading
                        st.error(f"{t('file_read_error')} {e}")
                        return 
                
                # Rerun ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏™‡∏Å‡∏±‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                st.rerun() 

            question_texts = st.session_state.question_texts
            if question_texts:
                st.success(t('extracted_questions').format(count=len(question_texts), filename=uploaded_file.name))
            


    # --- Step 2: Start Analysis ---
    st.markdown("---")
    st.header(t('step2_title'))
    
    # ‡πÉ‡∏ä‡πâ Callback function ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Rerun ‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô)
    def start_analysis_callback():
        if not GEMINI_AVAILABLE:
            st.error(t('api_not_ready'))
            return
            
        question_texts = st.session_state.question_texts
        analysis_results = []
        
        # ‡πÉ‡∏ä‡πâ st.status ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        with st.status(t('starting_analysis'), expanded=True) as status_box:
            
            st.write(t('preparing_analysis').format(count=len(question_texts), model=GEMINI_BATCH_MODEL_NAME))
            progress_bar = st.progress(0, text=t('analysis_progress').format(current=0, total=len(question_texts)))
            
            for i, q_text in enumerate(question_texts):
                st.write(t('analyzing_question').format(num=i+1))
                analysis = analyze_with_gemini(q_text, question_id=i+1)
                analysis["question_text"] = q_text 
                analysis_results.append(analysis)
                
                progress_percent = (i + 1) / len(question_texts)
                progress_bar.progress(progress_percent, text=t('analysis_progress').format(current=i+1, total=len(question_texts)))
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á‡πÉ‡∏ô session state
            st.session_state.analysis_results = analysis_results
            
            # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
            status_box.update(label=t('analysis_complete'), state="complete", expanded=False)


    if st.session_state.question_texts and st.button(
        t('start_analysis_btn'), 
        type="primary", 
        use_container_width=True,
        on_click=start_analysis_callback 
    ):
        pass


    # --- Step 3: Report ---
    if st.session_state.analysis_results:
        st.divider()
        st.header(t('step3_title'))

        all_analysis = st.session_state.analysis_results
        successful_analysis = [a for a in all_analysis if a.get('bloom_level') != "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ"]
        bloom_check = check_bloom_criteria(successful_analysis)
        summary_data, df = create_analysis_report(all_analysis, bloom_check)
        
        # ‡∏î‡∏∂‡∏á valid_total ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á (‡πÅ‡∏Å‡πâ NameError)
        valid_total = summary_data["‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î"].get("valid_total", 0)

        # ‡πÉ‡∏ä‡πâ Tabs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
        # *** ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏•‡∏ö tab_raw ‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ ***
        tab_summary, tab_details = st.tabs([t('tab_summary'), t('tab_details')])

        # --- Tab: Summary ---
        with tab_summary:
            st.subheader(t('summary_title'))
            stats = summary_data["‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°"]
            col1, col2, col3, col4 = st.columns(4) 

            # Helper function to extract percent value
            def get_percent_delta(text):
                try: 
                    return text.split('(')[1].strip('%)') 
                except IndexError: 
                    return "0.0%"

            # Good Questions Metric
            good_count_str = stats["‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏î‡∏µ** (‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)"].split(' ')[0]
            good_percent_str = get_percent_delta(stats["‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏î‡∏µ** (‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)"])
            col1.metric(t('good_questions'), good_count_str, delta=f"{good_percent_str}%", delta_color="normal")
            
            # To Improve Metric
            improve_count_str = stats["‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á**"].split(' ')[0]
            improve_percent_str = get_percent_delta(stats["‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö **‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á**"])
            col2.metric(t('needs_improvement'), improve_count_str, delta=f"{improve_percent_str}%", delta_color="inverse")
            
            # Total Questions 
            col3.metric(t('total_questions'), stats["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"].split(' ')[0])
            
            # Successfully Analyzed
            col4.metric(t('analyzed_success'), stats["‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à"].split(' ')[0])
            
            st.markdown("---")
            st.subheader(t('bloom_criteria_title'))
            bloom_stats = summary_data["‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î"]
            
            if bloom_check['pass']:
                st.success(f"**üéâ {bloom_stats['‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°']}**")
            else:
                st.warning(f"**‚ùå {bloom_stats['‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°']}**")
                
            col_b1, col_b2, col_b3 = st.columns(3)
            col_b1.metric(t('bloom_low'), bloom_stats["‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏ï‡πà‡∏≥ (‡∏à‡∏≥/‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à) (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â§ 40%)"], delta=f"{t('target')} ‚â§ 40%")
            col_b2.metric(t('bloom_mid'), bloom_stats["‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏Å‡∏•‡∏≤‡∏á (‡πÉ‡∏ä‡πâ/‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå) (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â• 50%)"], delta=f"{t('target')} ‚â• 50%")
            col_b3.metric(t('bloom_high'), bloom_stats["‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏π‡∏á (‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô/‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå) (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚â• 10%)"], delta=f"{t('target')} ‚â• 10%")
            
            st.markdown(f"{t('unidentified_bloom')} {bloom_stats['‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ']}")
            
            
            # --- ‡∏™‡∏£‡πâ‡∏≤‡∏á Pie Chart ‡πÅ‡∏•‡∏∞ ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ ---
            st.markdown("---")
            st.subheader(t('bloom_distribution'))
            
            col_chart, col_table = st.columns([1, 1.2]) 

            # 1. Pie Chart 
            with col_chart:
                bloom_counts = bloom_stats['raw_counts']
                # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Pie Chart (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° Unknown)
                chart_data_raw = {
                    '‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom': list(bloom_counts.keys())[:-1],
                    '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠': list(bloom_counts.values())[:-1],
                    '‡∏™‡∏µ': [get_bloom_color(level) for level in list(bloom_counts.keys())[:-1]]
                }
                chart_df = pd.DataFrame(chart_data_raw)
                
                if not chart_df.empty and chart_df['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠'].sum() > 0:
                    base = alt.Chart(chart_df).encode(
                        theta=alt.Theta("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠", stack=True)
                    )
                    
                    pie = base.mark_arc(outerRadius=120).encode(
                        color=alt.Color("‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom", scale=alt.Scale(domain=chart_df['‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom'].tolist(), range=chart_df['‡∏™‡∏µ'].tolist())),
                        order=alt.Order("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠", sort="descending"),
                        tooltip=["‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠"]
                    )
                    
                    st.altair_chart(pie, use_container_width=True)
                else:
                    st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom ‡πÑ‡∏î‡πâ")
            
            # 2. ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û/‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom
            with col_table:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏£‡∏∏‡∏õ
                summary_table_data = []
                for level, count in bloom_stats['raw_counts'].items():
                    if level == 'Unknown': continue 
                    
                    level_items = [a for a in all_analysis if level.lower() in a.get('bloom_level', '').lower()]
                    good_count = sum(1 for a in level_items if a.get('is_good_question') is True)
                    
                    percent_text = f"{round((count / valid_total) * 100, 1) if valid_total > 0 else 0}%"
                    
                    summary_table_data.append({
                        '‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom': level,
                        '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠': count,
                        '‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô': percent_text,
                        '‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ': good_count,
                        '‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á': count - good_count
                    })
                
                summary_table_df = pd.DataFrame(summary_table_data)
                
                st.markdown("**‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom**")
                st.dataframe(
                    summary_table_df, 
                    hide_index=True, 
                    use_container_width=True,
                    column_config={
                        '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠': st.column_config.NumberColumn(format="%d ‡∏Ç‡πâ‡∏≠"),
                        '‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ': st.column_config.NumberColumn(format="%d ‡∏Ç‡πâ‡∏≠"),
                        '‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á': st.column_config.NumberColumn(format="%d ‡∏Ç‡πâ‡∏≠"),
                    }
                )

        # --- Tab: Details ---
        with tab_details:
            st.subheader(t('details_title'))
            
            # 1. ‡πÅ‡∏™‡∏î‡∏á DataFrame ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡πà‡∏≠‡∏ô
            st.dataframe(
                df[[
                    '‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà', '‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö', '‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î', 
                    '‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£', '‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö', '‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠', 
                    '‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞'
                ]],
                column_config={
                    "‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö": st.column_config.Column("‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö", width="small"),
                    "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î": st.column_config.Column("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î", width="small"),
                    "‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠": st.column_config.Column("‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠", width="medium"),
                },
                use_container_width=True,
                hide_index=True
            )
            
            # 2. Loop ‡∏™‡∏£‡πâ‡∏≤‡∏á expander ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ç‡πâ‡∏≠
            st.markdown("---")
            st.markdown(t('click_detail'))
            
            for q_index, item in enumerate(all_analysis):
                quality_status = t('good') if item.get('is_good_question') is True and item.get('bloom_level') != "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ" else t('improve')
                expander_title = f"**{t('question_num')} {q_index+1}** | {quality_status} | {t('bloom_level')}: **{item.get('bloom_level', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}**"
                
                # ‡πÉ‡∏ä‡πâ st.expander ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
                with st.expander(expander_title):
                    
                    st.markdown(t('full_question'))
                    st.code(item.get('question_text', 'N/A'), language='markdown')
                    
                    st.markdown("---")

                    # ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏ä‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏™‡∏µ‡∏™‡∏±‡∏ô‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏° 
                    bloom_color = get_bloom_color(item.get('bloom_level', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'))
                    text_color = get_text_color_for_bloom(item.get('bloom_level', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'))
                    
                    col_det1, col_det2, col_det3 = st.columns([1, 1, 1]) 

                    with col_det1:
                        # ‡πÅ‡∏™‡∏î‡∏á Bloom Level
                        st.markdown(
                            f"""
                            <div style='background-color:{bloom_color}; color:{text_color}; padding: 10px; border-radius: 5px; text-align: center; margin-bottom: 10px;'>
                                <strong>üí° ‡∏£‡∏∞‡∏î‡∏±‡∏ö Bloom:</strong> {item.get('bloom_level', 'N/A')}
                            </div>
                            """, unsafe_allow_html=True
                        )
                    
                    with col_det2:
                         # ‡πÅ‡∏™‡∏î‡∏á Difficulty (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏™‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)
                        difficulty_level = item.get('difficulty', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
                        difficulty_color = {"‡∏á‡πà‡∏≤‡∏¢": "#008000", "‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á": "#FFA500", "‡∏¢‡∏≤‡∏Å": "#FF4500"}.get(difficulty_level, "#808080")
                        
                        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ï‡∏≤‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á
                        if difficulty_level in ["‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á"]: 
                            difficulty_text_color = "white" 
                        else:
                            difficulty_text_color = "white"
                        
                        st.markdown(
                            f"""
                            <div style='background-color:{difficulty_color}; color:{difficulty_text_color}; padding: 10px; border-radius: 5px; text-align: center; margin-bottom: 10px;'>
                                <strong>{t('difficulty')}</strong> {difficulty_level}
                            </div>
                            """, unsafe_allow_html=True
                        )

                    with col_det3:
                        # ‡πÅ‡∏™‡∏î‡∏á Correct Option
                        st.markdown(
                            f"""
                            <div style='background-color:#0077B6; color:white; padding: 10px; border-radius: 5px; text-align: center; margin-bottom: 10px;'>
                                <strong>{t('correct_answer')}</strong> {item.get('correct_option', 'N/A')}
                            </div>
                            """, unsafe_allow_html=True
                        )

                    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å 
                    st.markdown(f"{t('curriculum_indicator')} `{item.get('curriculum_standard', 'N/A')}`")
                    st.markdown(f"{t('bloom_reason')} {item.get('reasoning', 'N/A')}")
                    
                    st.divider()
                    st.subheader(t('answer_analysis_title'))
                    st.markdown(f"{t('correct_analysis')} {item.get('correct_option_analysis', 'N/A')}")
                    st.markdown(f"{t('distractor_analysis')} {item.get('distractor_analysis', 'N/A')}")
                    st.markdown(f"{t('why_good_distractor')} {item.get('why_good_distractor', 'N/A')}")
                    
                    st.warning(f"{t('improvement_suggestion')} {item.get('improvement_suggestion', 'N/A')}")
                
                st.divider() 


        # --- Tab: Raw JSON ---
        # (‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ)


if __name__ == "__main__":
    run_app()